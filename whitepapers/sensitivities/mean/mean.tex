\documentclass[11pt]{scrartcl} % Font size
\input{../structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{
	\normalfont\normalsize
	\textsc{Harvard Privacy Tools Project}\\ % Your university, school and/or department name(s)
	\vspace{25pt} % Whitespace
	\rule{\linewidth}{0.5pt}\\ % Thin top horizontal rule
	\vspace{20pt} % Whitespace
	{\huge Mean Sensitivity Proofs}\\ % The assignment title
	\vspace{12pt} % Whitespace
	\rule{\linewidth}{2pt}\\ % Thick bottom horizontal rule
	\vspace{12pt} % Whitespace
}

% \author{\LARGE} % Your name

\date{\normalsize\today} % Today's date (\today) or a custom date

\begin{document}

\maketitle

\begin{definition}
The sample mean of database $X$ of size $n$ is defined as 
$$f(X) = \frac{1}{n} \sum_{i=1}^n x_i.$$
\end{definition}
These are restricted-sensitivity proofs that only apply when N is known.
The library makes use of the Resize component to guarantee this static property.
If N is unknown, there is an argument on the DPMean component to estimate the mean by postprocessing plug-in estimates for the count and sum.

\section{Neighboring Definition: Change One}

% l1 sensitivity
\subsection{$\ell_1$-sensitivity}
\begin{theorem}
Say the space of datapoints $\mathcal{X}$ is bounded above by $M$ and bounded below by $m$. Then $f(\cdot)$ has $\ell_1$-sensitivity in the change-one model bounded above by
$$ \frac{M-m}{n}.$$
\end{theorem}

\begin{proof}
Say $X$ and $X'$ are neighboring databases which differ at data-point $x_j$, and let $\Delta{f}$ indicate the $\ell_1$-sensitivity of $f(\cdot)$. Then
\begin{align*}
\Delta{f} &= \max_{X,X'} \left\vert f(X) - f(X)' \right\vert \\
	&=  \max_{X,X'} \frac{1}{n} \left\vert \left(\sum_{\{ i \in [n] \vert i \ne j\}} x_i\right) + x_j  - \left(\sum_{\{ i \in [n] \vert i \ne j\}} x_i'\right) + x_j'  \right\vert \\
	&= \max_{X,X'} \frac{1}{n} \left\vert x_j - x_j' \right\vert \\
	&\le \frac{M-m}{n}.
\end{align*}
\end{proof}

% l2 sensitivity
\subsection{$\ell_2$-sensitivity}
\begin{theorem}
	Say the space of datapoints $\mathcal{X}$ is bounded above by $M$ and bounded below by $m$.
	Then $f(\cdot)$ has $\ell_2$-sensitivity in the change-one model bounded above by
	 $$ \frac{M-m}{n}. $$
\end{theorem}

\begin{proof}
This follows the same logic as the above proof.
\end{proof}

\section{Neighboring Definition: Add/Drop One}
\subsection{$\ell_1$-sensitivity}

\begin{theorem}
Say the space of datapoints $\mathcal{X}$ is bounded above by $M$ and bounded below by $m$.
Then $f(\cdot)$ has $\ell_1$-sensitivity in the add/drop-one model bounded above by
$$ \frac{M-m}{n}. $$
\end{theorem}

\begin{proof}
For notational ease, let $n$ always refer to the size of database $x$. We must consider both adding and removing an element from $x$. First, consider adding a point:\\

Let $X' = X \cup \{x\}$. Without loss of generality, assume the point added is the $(n+1)^{\text{th}}$ element of database $X'$. Note that
\begin{align*}
\left \vert f(X) - f(X)' \right\vert &= \left\vert \frac{1}{n} \sum_{i=1}^n x_i - \frac{1}{n+1} \sum_{i=1}^{n+1} x_i \right\vert \\
	&= \left\vert \left(\frac{1}{n} - \frac{1}{n+1}\right) \sum_{i=1}^n x_i - \frac{x}{n+1}\right\vert \\
	&= \frac{1}{n+1} \left\vert \frac{1}{n} \sum_{i=1}^n x_i - x \right\vert \\
	&\le \frac{ \left\vert M - m \right\vert}{n+1}.
\end{align*}

Second, consider removing a point: \\
Let $X' = X\textbackslash\{x\}$. Without loss of generality assume that the point subtracted is the $n^{\text{th}}$ element of database $X$.
\begin{align*}
\left \vert f(X) - f(X') \right\vert &= \left\vert \frac{1}{n-1} \sum_{i=1}^{n-1} x_i - \frac{1}{n} \sum_{i=1}^n x_i \right\vert \\
	&= \left\vert \left(\frac{1}{n-1} - \frac{1}{n}\right) \sum_{i=1}^{n-1} x_i - \frac{x}{n}\right\vert \\
	&= \frac{1}{n} \left\vert \frac{1}{n-1} \sum_{i=1}^{n-1} x_i  - x \right\vert \\
	&\le \frac{\left\vert M-m\right\vert}{n}.
\end{align*}

Then, since $\forall n > 0,$

$$ \frac{1}{n+1} < \frac{1}{n},$$

the sensitivity of the mean in general is bound from above by 

$$ \frac{M-m}{n}.$$
\end{proof}

% l2 sensitivity
\subsection{$\ell_2$-sensitivity}

\begin{theorem}
Say the space of datapoints $\mathcal{X}$ is bounded above by $M$ and bounded below by $m$. Then $f$ has $\ell_2$-sensitivity in the add/drop-one model bounded above by
	$$ \frac{M-m}{n}. $$
\end{theorem}

\begin{proof}
This follows the same logic as the above proof.
%	For notational ease, let $n$ always refer to the size of database $X$. We must consider both adding and removing an element from $X$. First, consider adding a point:
%
%	Let $X' = X \cup x$. Without loss of generality assume the point added is the $(n+1)^\text{th}$ element of database X'. Then,
%	\begin{align*}
%		\Delta f &= \max_{X,X'} \sqrt{(f(X)- f(X)')^2} \\
%					   &= \max_{X,X'} \left( \frac{1}{n}\sum_{i=1}^{n}x_i - \frac{1}{n+1}\sum_{i=1}^{n+1}x'_i \right)\\
%					   &= \max_{X,X'} \left( \left(\frac{1}{n}\sum_{i=1}^{n}x_i\right) - \left(\frac{1}{n+1}\sum_{i=1}^{n}x'_i\right) - \frac{x}{n+1} \right)\\
%					   &= \max_{X,X'} \left( \frac{ \left(\sum_{i=1}^{n}x_i\right) - nx }{n(n+1)} \right)\\
%					   &= \frac{nM - nm}{n(n+1)}\\
%					   &= \frac{M - m}{n+1}.
%	\end{align*}
%
%Second, consider removing an element:\\
%Let $X' = X \setminus \{ x \}$. Without loss of generality assume that the point subtracted is the $n^\text{th}$ element of database $X$. Then,
%	\begin{align*}
%		\Delta f &= \max_{X,X'} (f(X)- f(X)')^2 \\
%					   &= \max_{X,X'} \left( \frac{1}{n}\sum_{i=1}^{n}x_i - \frac{1}{n-1}\sum_{i=1}^{n-1}x'_i \right)\\
%					   &= \max_{X,X'} \left( \left( \frac{1}{n}\sum_{i=1}^{n-1}x_i \right) + \frac{x}{n} - \left( \frac{1}{n-1}\sum_{i=1}^{n-1}x'_i \right) \right) \\
%					   &= \max_{X,X'} \left( \frac{(n-1)x - \sum_{i=1}^{n-1}x_i }{n(n-1)} \right) \\
%					   &= \frac{(n-1)M - (n-1)m}{n(n-1)} \\
%					   &= \frac{M-m}{n}
%	\end{align*}
%	
%Then, since $\forall n > 0,$
%
%$$ \frac{1}{n+1} < \frac{1}{n},$$
%
%the sensitivity of the mean in general is bound from above by 
%
%$$ \frac{M-m}{n}.$$
\end{proof}

% \bibliographystyle{alpha}
% \bibliography{mean}

\end{document}